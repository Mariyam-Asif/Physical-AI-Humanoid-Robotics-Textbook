---
id: glossary
title: Glossary
sidebar_label: Glossary
tags: ['glossary', 'definitions', 'terms']
learning_objectives:
  - Understand key terminology used in Physical AI and Humanoid Robotics.
  - Quickly reference definitions for technical terms.
---

# Glossary of Terms

This glossary provides definitions for key terms and concepts encountered throughout the Physical AI & Humanoid Robotics textbook. It is designed to be a quick reference for students, practitioners, and enthusiasts alike.

## A

**Actuator**: A component of a machine that is responsible for moving or controlling a mechanism or system. It takes energy, usually created by air, electric current, or liquid, and converts that into some kind of motion.

**Artificial Intelligence (AI)**: The simulation of human intelligence processes by machines, especially computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction.

## B

**Behavioral Robotics**: A subfield of robotics that focuses on building robots that can react to their environment in a more biologically inspired way, often through a collection of simple, independent behaviors.

## C

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos and deep learning models, machines can accurately identify and classify objects, then react to what they 'see'.

## D

**Digital Twin**: A virtual model designed to accurately reflect a physical object. The digital twin is integrated with IoT sensors that collect real-time data from the physical object. This data can then be used to simulate and predict the behavior of the physical object.

## E

**End-effector**: A device or tool connected to the end of a robot arm, designed to interact with the environment. It can be a gripper, a welding torch, a camera, or other tools.

## F

**Force Sensor**: A transducer that converts an input mechanical force into an electrical output signal. Used in robotics to measure interaction forces with the environment.

## G

**Gazebo**: A powerful 3D robotics simulator that allows for accurate simulation of robots in complex indoor and outdoor environments. It generates realistic sensor feedback and physically accurate interactions.

## H

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots. It is often referred to as the study of how humans and robots can work together effectively and safely.

**Humanoid Robot**: A robot with its overall body shape built to resemble the human body. Humanoid robots can be bipedal (walking on two legs) or have a torso, head, two arms, and two legs.

## I

**Inverse Kinematics (IK)**: In robotics, inverse kinematics is the process of calculating the joint parameters that provide a desired position and orientation for the end-effector of a robot arm.

## L

**LIDAR (Light Detection and Ranging)**: A remote sensing method that uses pulsed laser to measure ranges (variable distances) to the Earth. Used in robotics for mapping and navigation.

## M

**Machine Learning (ML)**: A subset of artificial intelligence that enables systems to learn from data without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.

**Manipulation**: In robotics, the ability of a robot to grasp, move, and otherwise interact with objects in its environment.

## N

**NVIDIA Isaac**: A platform for developing, simulating, and deploying AI-powered robots. It provides tools for robotics perception, navigation, and manipulation.

## P

**Perception**: The ability of a robotic system to interpret sensor data (e.g., from cameras, LiDAR, force sensors) to understand its environment.

**Physical AI**: A branch of artificial intelligence that deals with embodied intelligence, focusing on how AI can be integrated into physical systems like robots to enable intelligent behavior in the real world.

## R

**Reinforcement Learning (RL)**: An area of machine learning concerned with how intelligent agents ought to take actions in an environment to maximize the notion of cumulative reward. It is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.

**Robot Operating System (ROS)**: A flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.

**ROS 2**: The second generation of the Robot Operating System, designed for improved performance, security, and real-time capabilities, making it suitable for production robotics.

## S

**Sensor**: A device that detects and responds to some type of input from the physical environment. The specific input could be light, heat, motion, moisture, pressure, or any one of a great number of other environmental phenomena.

**SLAM (Simultaneous Localization and Mapping)**: A computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

## U

**Unity (Unity 3D)**: A cross-platform game engine developed by Unity Technologies, used for developing video games, simulations for robotics, and virtual reality.

## V

**Vision-Language-Action (VLA)**: An emerging field in AI and robotics that aims to create agents capable of understanding their environment through vision, interpreting instructions through natural language, and performing complex tasks through physical action. It focuses on bridging the gap between perception, cognition, and physical embodiment.

